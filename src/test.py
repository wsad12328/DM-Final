import os
import pandas as pd
import numpy as np
import argparse
import torch
import joblib
import pickle
from utils.io_utils import load_preprocessed_data, load_model, load_label_encoders
from models.MLP import MLP
from utils.feature_utils import get_cat_cardinalities

NUM_CLASS = 7  # Number of fertilizer classes

def load_lightgbm_model(model_path):
    """è¼‰å…¥ LightGBM æ¨¡åž‹"""
    with open(model_path, 'rb') as f:
        model_data = joblib.load(f)
    
    if isinstance(model_data, dict):
        return model_data['model'], model_data.get('label_encoder', None)
    else:
        return model_data, None

def predict_lightgbm(model, X_test, cat_cols, label_encoder=None):
    """LightGBM é æ¸¬ï¼ˆè™•ç†åˆ†é¡žç‰¹å¾µï¼‰"""
    X_test_lgb = X_test.copy()
    for col in cat_cols:
        if col in X_test_lgb.columns:
            X_test_lgb[col] = X_test_lgb[col].astype('category')
    
    try:
        proba = model.predict_proba(X_test_lgb)
        return proba
    except Exception as e:
        print(f"âš ï¸ LightGBM prediction error: {e}")
        # Fallback: ä¸ä½¿ç”¨åˆ†é¡žç‰¹å¾µ
        try:
            proba = model.predict_proba(X_test)
            return proba
        except Exception as e2:
            print(f"âŒ LightGBM prediction failed completely: {e2}")
            raise e2

def predict_mlp(encoding_method, X_test, num_cols, cat_cols, fertilizer_le, n_folds=5):
    """MLP é æ¸¬ - é›†æˆå¤šå€‹ fold æ¨¡åž‹"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    num_x = X_test[num_cols].values.astype(np.float32)
    cat_x = X_test[cat_cols].values.astype(np.int64)
    numeric_num_features = num_x.shape[1]
    cat_cardinalities = get_cat_cardinalities(cat_x)
    output_dim = len(fertilizer_le.classes_)

    pred_prob = np.zeros((len(X_test), output_dim))
    model_count = 0
    
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    for fold in range(n_folds):
        model_path = os.path.join(base_dir, '..', 'models', f'mlp_{encoding_method}_fold{fold+1}.pth')
        
        if not os.path.exists(model_path):
            print(f"âš ï¸ Model file not found: {model_path}")
            continue
            
        print(f"Loading MLP model from fold {fold+1}: {model_path}")
        
        try:
            # è¼‰å…¥æ¨¡åž‹
            model = MLP(numeric_num_features, cat_cardinalities, output_dim)
            model.load_state_dict(torch.load(model_path, weights_only=True))
            model.to(device)
            model.eval()

            # é æ¸¬
            with torch.no_grad():
                num_x_tensor = torch.tensor(num_x, dtype=torch.float32).to(device)
                cat_x_tensor = torch.tensor(cat_x, dtype=torch.long).to(device)
                logits = model(num_x_tensor, cat_x_tensor)
                fold_proba = torch.softmax(logits, dim=1).cpu().numpy()
            
            pred_prob += fold_proba
            model_count += 1
            print(f"âœ… Fold {fold+1} predictions added")
            
        except Exception as e:
            print(f"âŒ Fold {fold+1} prediction failed: {e}")
            continue
    
    if model_count == 0:
        raise ValueError("No MLP fold models found!")
    
    # å¹³å‡é æ¸¬çµæžœ
    pred_prob /= model_count
    print(f"ðŸ“Š Ensembled MLP predictions from {model_count} models")
    
    return pred_prob

def ensemble_tree_models(model_name, encoding_method, X_test, cat_cols, n_folds, base_dir):
    """é›†æˆæ¨¹æ¨¡åž‹é æ¸¬"""
    pred_prob = np.zeros((len(X_test), NUM_CLASS))
    model_count = 0
    
    for fold in range(n_folds):
        model_path = os.path.join(base_dir, '..', 'models', f'{model_name}_{encoding_method}_fold_{fold}.pkl')
        
        if not os.path.exists(model_path):
            print(f"âš ï¸ Model file not found: {model_path}")
            continue
            
        print(f"Loading model from fold {fold}: {model_path}")
        
        try:
            if model_name == 'lightgbm':
                model, label_encoder = load_lightgbm_model(model_path)
                fold_proba = predict_lightgbm(model, X_test, cat_cols, label_encoder)
            else:
                model = joblib.load(model_path)
                fold_proba = model.predict_proba(X_test)
            
            pred_prob += fold_proba
            model_count += 1
            print(f"âœ… Fold {fold} predictions added")
            
        except Exception as e:
            print(f"âŒ Fold {fold} prediction failed: {e}")
            continue
    
    if model_count == 0:
        raise ValueError("No fold models found!")
    
    # å¹³å‡é æ¸¬çµæžœ
    pred_prob /= model_count
    print(f"ðŸ“Š Ensembled predictions from {model_count} models")
    
    return pred_prob

def get_top3_predictions(proba):
    """ç²å– top3 é æ¸¬ç´¢å¼•"""
    return np.argsort(proba, axis=1)[:, ::-1][:, :3]

def decode_predictions(top3_idx, model_name, encoding_method, base_dir):
    """è§£ç¢¼é æ¸¬çµæžœç‚ºé¡žåˆ¥åç¨±"""
    if model_name == 'lightgbm':
        # LightGBM ç‰¹æ®Šè™•ç†
        sample_model_path = os.path.join(base_dir, '..', 'models', f'{model_name}_{encoding_method}_fold_0.pkl')
        model, label_encoder = load_lightgbm_model(sample_model_path)
        
        if label_encoder is not None:
            # ä½¿ç”¨æ¨™ç±¤ç·¨ç¢¼å™¨è§£ç¢¼
            return label_encoder.inverse_transform(top3_idx.ravel()).reshape(top3_idx.shape)
        else:
            # ä½¿ç”¨æ¨¡åž‹çš„ classes_ å±¬æ€§
            return model.classes_[top3_idx]
    else:
        # å…¶ä»–æ¨¡åž‹
        sample_model_path = os.path.join(base_dir, '..', 'models', f'{model_name}_{encoding_method}_fold_0.pkl')
        model = joblib.load(sample_model_path)
        return model.classes_[top3_idx]

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--encoding', choices=['label', 'onehot'], default='label', help="Encoding method")
    parser.add_argument('--model', choices=['xgboost', 'random_forest', 'mlp', 'catboost', 'lightgbm'], default='xgboost', help="Model name")
    parser.add_argument('--n_folds', type=int, default=5, help="Number of folds to ensemble")
    args = parser.parse_args()

    # è¼‰å…¥æ•¸æ“šå’Œç·¨ç¢¼å™¨
    base_dir = os.path.dirname(os.path.abspath(__file__))
    df_test = load_preprocessed_data(data_type='test', encoding_method=args.encoding)
    label_encoders = load_label_encoders()
    fertilizer_le = label_encoders['Fertilizer Name']

    # è¼‰å…¥åˆ—ä¿¡æ¯
    cols_info_path = os.path.join(base_dir, f'../data/cols_info_test_{args.encoding}.pkl')
    with open(cols_info_path, 'rb') as f:
        cols = pickle.load(f)
    num_cols = cols['num_cols']
    cat_cols = cols['cat_cols']

    # æº–å‚™æ¸¬è©¦æ•¸æ“š
    id_col = df_test['id']
    X_test = df_test.drop(columns=['id'])

    # æ ¹æ“šæ¨¡åž‹é¡žåž‹é€²è¡Œé æ¸¬
    if args.model == 'mlp':
        proba = predict_mlp(args.encoding, X_test, num_cols, cat_cols, fertilizer_le)
        top3_idx = get_top3_predictions(proba)
        top3_labels = fertilizer_le.inverse_transform(top3_idx.ravel()).reshape(top3_idx.shape)
        model_count = 1
    else:
        # æ¨¹æ¨¡åž‹é›†æˆé æ¸¬
        pred_prob = ensemble_tree_models(args.model, args.encoding, X_test, cat_cols, args.n_folds, base_dir)
        top3_idx = get_top3_predictions(pred_prob)
        top3_preds = decode_predictions(top3_idx, args.model, args.encoding, base_dir)
        
        # æœ€çµ‚è§£ç¢¼ç‚ºè‚¥æ–™åç¨±
        if isinstance(top3_preds[0, 0], str):
            # å¦‚æžœå·²ç¶“æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æŽ¥ä½¿ç”¨
            top3_labels = top3_preds
        else:
            # å¦å‰‡ä½¿ç”¨ fertilizer_le è§£ç¢¼
            top3_labels = fertilizer_le.inverse_transform(top3_preds.ravel()).reshape(top3_preds.shape)
        
        model_count = args.n_folds

    # ç”Ÿæˆæäº¤æ–‡ä»¶
    submission = pd.DataFrame({
        'id': id_col,
        'Fertilizer Name': [' '.join(preds) for preds in top3_labels]
    })

    # ä¿å­˜çµæžœ
    suffix = f"_ensemble_{model_count}folds" if model_count > 1 else ""
    output_path = os.path.join(base_dir, '../result', f'submission_{args.model}_{args.encoding}{suffix}.csv')
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    submission.to_csv(output_path, index=False)
    print(f"âœ… Submission saved to: {output_path}")

if __name__ == '__main__':
    main()